{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading SteamSpy Pages: 36page [01:56,  3.25s/page, Page 35 saved]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on page 36: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create output directory if not exists\n",
    "output_dir = \"steamspy_pages\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "page = 0\n",
    "pbar = tqdm(desc=\"Downloading SteamSpy Pages\", unit=\"page\")\n",
    "\n",
    "while True:\n",
    "    url = f\"https://steamspy.com/api.php?request=all&page={page}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        if not data:\n",
    "            print(\"No more data. Exiting loop.\")\n",
    "            break\n",
    "\n",
    "        # Convert JSON dict to DataFrame\n",
    "        df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "        # Save to CSV\n",
    "        filename = os.path.join(output_dir, f\"steamspy_page_{page}.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix_str(f\"Page {page} saved\")\n",
    "\n",
    "        # Sleep to avoid hitting the request limit\n",
    "        time.sleep(3)\n",
    "        page += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "        break\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 fetched successfully.\n",
      "Page 2 fetched successfully.\n",
      "Page 3 fetched successfully.\n",
      "Page 4 fetched successfully.\n",
      "Page 5 fetched successfully.\n",
      "Page 6 fetched successfully.\n",
      "Page 7 fetched successfully.\n",
      "Page 8 fetched successfully.\n",
      "Page 9 fetched successfully.\n",
      "Page 10 fetched successfully.\n",
      "Page 11 fetched successfully.\n",
      "Page 12 fetched successfully.\n",
      "Page 13 fetched successfully.\n",
      "Page 14 fetched successfully.\n",
      "Page 15 fetched successfully.\n",
      "Page 16 fetched successfully.\n",
      "Page 17 fetched successfully.\n",
      "Page 18 fetched successfully.\n",
      "Page 19 fetched successfully.\n",
      "Page 20 fetched successfully.\n",
      "Page 21 fetched successfully.\n",
      "Page 22 fetched successfully.\n",
      "Page 23 fetched successfully.\n",
      "Page 24 fetched successfully.\n",
      "Page 25 fetched successfully.\n",
      "Page 26 fetched successfully.\n",
      "Page 27 fetched successfully.\n",
      "Page 28 fetched successfully.\n",
      "Page 29 fetched successfully.\n",
      "Page 30 fetched successfully.\n",
      "Page 31 fetched successfully.\n",
      "Page 32 fetched successfully.\n",
      "Page 33 fetched successfully.\n",
      "Page 34 fetched successfully.\n",
      "Page 35 fetched successfully.\n",
      "Page 36 fetched successfully.\n",
      "Page 37 fetched successfully.\n",
      "Page 38 fetched successfully.\n",
      "Page 39 fetched successfully.\n",
      "Page 40 fetched successfully.\n",
      "Page 41 fetched successfully.\n",
      "Page 42 fetched successfully.\n",
      "Page 43 fetched successfully.\n",
      "Page 44 fetched successfully.\n",
      "Page 45 fetched successfully.\n",
      "Page 46 fetched successfully.\n",
      "Page 47 fetched successfully.\n",
      "Page 48 fetched successfully.\n",
      "Page 49 fetched successfully.\n",
      "Page 50 fetched successfully.\n",
      "Page 51 fetched successfully.\n",
      "Page 52 fetched successfully.\n",
      "Page 53 fetched successfully.\n",
      "Page 54 fetched successfully.\n",
      "Page 55 fetched successfully.\n",
      "Page 56 fetched successfully.\n",
      "Page 57 fetched successfully.\n",
      "Page 58 fetched successfully.\n",
      "Page 59 fetched successfully.\n",
      "Page 60 fetched successfully.\n",
      "Page 61 fetched successfully.\n",
      "Page 62 fetched successfully.\n",
      "Page 63 fetched successfully.\n",
      "Page 64 fetched successfully.\n",
      "Page 65 fetched successfully.\n",
      "Page 66 fetched successfully.\n",
      "Page 67 fetched successfully.\n",
      "Page 68 fetched successfully.\n",
      "Page 69 fetched successfully.\n",
      "Page 70 fetched successfully.\n",
      "Page 71 fetched successfully.\n",
      "Page 72 fetched successfully.\n",
      "Page 73 fetched successfully.\n",
      "Page 74 fetched successfully.\n",
      "Page 75 fetched successfully.\n",
      "Page 76 fetched successfully.\n",
      "Page 77 fetched successfully.\n",
      "Page 78 fetched successfully.\n",
      "Page 79 fetched successfully.\n",
      "Page 80 fetched successfully.\n",
      "Page 81 fetched successfully.\n",
      "Page 82 fetched successfully.\n",
      "Page 83 fetched successfully.\n",
      "Page 84 fetched successfully.\n",
      "Page 85 fetched successfully.\n",
      "Page 86 fetched successfully.\n",
      "Page 87 fetched successfully.\n",
      "Page 88 fetched successfully.\n",
      "Page 89 fetched successfully.\n",
      "Page 90 fetched successfully.\n",
      "Page 91 fetched successfully.\n",
      "Page 92 fetched successfully.\n",
      "Page 93 fetched successfully.\n",
      "Page 94 fetched successfully.\n",
      "Page 95 fetched successfully.\n",
      "Page 96 fetched successfully.\n",
      "Page 97 fetched successfully.\n",
      "Page 98 fetched successfully.\n",
      "Page 99 fetched successfully.\n",
      "Page 100 fetched successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "appid=2246340 #2767030\n",
    "num_pages=10\n",
    "\n",
    "def fetch_reviews(appid, num_pages=10, delay=1):\n",
    "    all_reviews = []\n",
    "    cursor = '*'\n",
    "\n",
    "    for page in range(num_pages):\n",
    "        params = {\n",
    "            'json': 1,\n",
    "            'filter': 'recent',\n",
    "            'language': 'english', \n",
    "            'purchase_type': 'all',\n",
    "            'cursor': cursor\n",
    "        }\n",
    "        response = requests.get(f'https://store.steampowered.com/appreviews/{appid}', params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch data: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        reviews = data.get('reviews', [])\n",
    "        if not reviews:\n",
    "            print(\"No more reviews available.\")\n",
    "            break\n",
    "\n",
    "        for review in reviews:\n",
    "            author = review.get('author', {})\n",
    "            review_data = {\n",
    "                'steamid': author.get('steamid'),\n",
    "                'num_games_owned': author.get('num_games_owned'),\n",
    "                'num_reviews': author.get('num_reviews'),\n",
    "                'playtime_forever': author.get('playtime_forever'),\n",
    "                'playtime_last_two_weeks': author.get('playtime_last_two_weeks'),\n",
    "                'review_text': review.get('review'),\n",
    "                'timestamp_created': review.get('timestamp_created'),\n",
    "                'voted_up': review.get('voted_up'),\n",
    "                'votes_up': review.get('votes_up'),\n",
    "                'votes_funny': review.get('votes_funny')\n",
    "            }\n",
    "            all_reviews.append(review_data)\n",
    "\n",
    "        cursor = data.get('cursor', '')\n",
    "        if not cursor:\n",
    "            print(\"No further cursor found, ending pagination.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Page {page + 1} fetched successfully.\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    return all_reviews\n",
    "\n",
    "# Fetch reviews for Marvel Rivals (AppID: 2767030)\n",
    "reviews = fetch_reviews(appid, num_pages)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n",
    "\n",
    "# Optionally, save to CSV\n",
    "df.to_csv(f\"./reviews/{appid}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "Successfully installed dotenv-0.9.9 python-dotenv-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for user 76561199180420704: 51 games\n",
      "Collected data for user 76561198401542106: 41 games\n",
      "Collected data for user 76561197998914389: 431 games\n",
      "Collected data for user 76561198079700490: 182 games\n",
      "Users: 4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "API_KEY = os.getenv(\"STEAM_API_KEY\")\n",
    "\n",
    "steam_ids = df[\"steamid\"].to_list()[0:10]\n",
    "\n",
    "\n",
    "def collect_user_data(steam_ids, api_key):\n",
    "    \"\"\"Collect game libraries and playtime for multiple users\"\"\"\n",
    "    user_data = []\n",
    "    \n",
    "    for steam_id in steam_ids:\n",
    "        try:\n",
    "            url = f\"https://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key={api_key}&steamid={steam_id}&format=json&include_appinfo=1\"\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'response' in data and 'games' in data['response']:\n",
    "                    user_data.append({\n",
    "                        'steam_id': steam_id,\n",
    "                        'response': data['response']\n",
    "                    })\n",
    "                    print(f\"Collected data for user {steam_id}: {len(data['response']['games'])} games\")\n",
    "            \n",
    "            # Respect API rate limits\n",
    "            time.sleep(1.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting data for user {steam_id}: {e}\")\n",
    "    \n",
    "    # Save the collected data\n",
    "    with open(f'users/user_data.json', 'w') as f:\n",
    "        json.dump(user_data, f)\n",
    "    \n",
    "    return user_data\n",
    "\n",
    "# Execute data collection\n",
    "user_data = collect_user_data(steam_ids, API_KEY)\n",
    "print(f\"Users: {len(user_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
