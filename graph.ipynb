{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765e03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "import torch_geometric\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7eebcf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bfb155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT-base\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "bert_model.eval()  # Evaluation mode (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a992ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_fantasy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45d8a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_steam_id</th>\n",
       "      <th>user_playtime_forever</th>\n",
       "      <th>user_playtime_2weeks</th>\n",
       "      <th>user_has_leaderboards</th>\n",
       "      <th>user_has_community_visible_stats</th>\n",
       "      <th>user_content_descriptorids</th>\n",
       "      <th>game_appid</th>\n",
       "      <th>game_name</th>\n",
       "      <th>game_developer</th>\n",
       "      <th>...</th>\n",
       "      <th>game_price</th>\n",
       "      <th>game_initialprice</th>\n",
       "      <th>game_discount</th>\n",
       "      <th>game_ccu</th>\n",
       "      <th>game_owners_estimate</th>\n",
       "      <th>game_review_ratio</th>\n",
       "      <th>genres_en</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>short_description_en</th>\n",
       "      <th>detailed_description_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>7279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[2, 5]</td>\n",
       "      <td>240</td>\n",
       "      <td>Counter-Strike: Source</td>\n",
       "      <td>Valve</td>\n",
       "      <td>...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15002</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0.962647</td>\n",
       "      <td>['Action']</td>\n",
       "      <td>['Multi-Player', 'Cross-Platform Multiplayer',...</td>\n",
       "      <td>Counter-Strike: Source blends Counter-Strike's...</td>\n",
       "      <td>THE NEXT INSTALLMENT OF THE WORLD'S # 1 ONLINE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0]</td>\n",
       "      <td>12210</td>\n",
       "      <td>Grand Theft Auto IV: The Complete Edition</td>\n",
       "      <td>Rockstar North, Rockstar Toronto</td>\n",
       "      <td>...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3464</td>\n",
       "      <td>5000000</td>\n",
       "      <td>0.823607</td>\n",
       "      <td>['Action', 'Adventure']</td>\n",
       "      <td>['Single-Player', 'Multi-Player', 'Partial Con...</td>\n",
       "      <td>Niko Bellic, Johnny Klebitz and Luis Lopez all...</td>\n",
       "      <td>Important Updates To Grand Theft Auto IV and E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0]</td>\n",
       "      <td>620</td>\n",
       "      <td>Portal 2</td>\n",
       "      <td>Valve</td>\n",
       "      <td>...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3194</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0.986921</td>\n",
       "      <td>['Action', 'Adventure']</td>\n",
       "      <td>['Single Person', 'Multiple People', 'Cooperat...</td>\n",
       "      <td>The Lifetime Test Plan is now upgraded and you...</td>\n",
       "      <td>Portal 2 creates another successor to the gran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>4578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[0]</td>\n",
       "      <td>105600</td>\n",
       "      <td>Terraria</td>\n",
       "      <td>Re-Logic</td>\n",
       "      <td>...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38390</td>\n",
       "      <td>20000000</td>\n",
       "      <td>0.974917</td>\n",
       "      <td>['Action', 'Adventure', 'Indie', 'Rpg']</td>\n",
       "      <td>['Single-Player', 'Multi-Player', 'Pvp', 'Onli...</td>\n",
       "      <td>Dig, fight, explore, build! Nothing is impossi...</td>\n",
       "      <td>Dig, Fight, Explore, Build: The very world is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>[0]</td>\n",
       "      <td>46520</td>\n",
       "      <td>Wasteland Angel</td>\n",
       "      <td>Octane Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>['Action', 'Indie']</td>\n",
       "      <td>['Single-Player', 'Steam Achievements', 'Parti...</td>\n",
       "      <td>Wasteland Angel is a top-down twin-stick shoot...</td>\n",
       "      <td>Bummer! World War III happened and killed most...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      user_steam_id  user_playtime_forever  user_playtime_2weeks  \\\n",
       "0           0  76561198060785055                   7279                   0.0   \n",
       "1           1  76561198060785055                      0                   0.0   \n",
       "2           2  76561198060785055                    717                   0.0   \n",
       "3           3  76561198060785055                   4578                   0.0   \n",
       "4           4  76561198060785055                      0                   0.0   \n",
       "\n",
       "   user_has_leaderboards  user_has_community_visible_stats  \\\n",
       "0                  False                              True   \n",
       "1                  False                              True   \n",
       "2                   True                              True   \n",
       "3                  False                              True   \n",
       "4                   True                              True   \n",
       "\n",
       "  user_content_descriptorids  game_appid  \\\n",
       "0                     [2, 5]         240   \n",
       "1                        [0]       12210   \n",
       "2                        [0]         620   \n",
       "3                        [0]      105600   \n",
       "4                        [0]       46520   \n",
       "\n",
       "                                   game_name  \\\n",
       "0                     Counter-Strike: Source   \n",
       "1  Grand Theft Auto IV: The Complete Edition   \n",
       "2                                   Portal 2   \n",
       "3                                   Terraria   \n",
       "4                            Wasteland Angel   \n",
       "\n",
       "                     game_developer  ... game_price  game_initialprice  \\\n",
       "0                             Valve  ...       9.99               9.99   \n",
       "1  Rockstar North, Rockstar Toronto  ...      19.99              19.99   \n",
       "2                             Valve  ...       9.99               9.99   \n",
       "3                          Re-Logic  ...       9.99               9.99   \n",
       "4                      Octane Games  ...       4.99               4.99   \n",
       "\n",
       "   game_discount  game_ccu  game_owners_estimate  game_review_ratio  \\\n",
       "0            0.0     15002              10000000           0.962647   \n",
       "1            0.0      3464               5000000           0.823607   \n",
       "2            0.0      3194              10000000           0.986921   \n",
       "3            0.0     38390              20000000           0.974917   \n",
       "4            0.0         0                 50000           0.587302   \n",
       "\n",
       "                                 genres_en  \\\n",
       "0                               ['Action']   \n",
       "1                  ['Action', 'Adventure']   \n",
       "2                  ['Action', 'Adventure']   \n",
       "3  ['Action', 'Adventure', 'Indie', 'Rpg']   \n",
       "4                      ['Action', 'Indie']   \n",
       "\n",
       "                                       categories_en  \\\n",
       "0  ['Multi-Player', 'Cross-Platform Multiplayer',...   \n",
       "1  ['Single-Player', 'Multi-Player', 'Partial Con...   \n",
       "2  ['Single Person', 'Multiple People', 'Cooperat...   \n",
       "3  ['Single-Player', 'Multi-Player', 'Pvp', 'Onli...   \n",
       "4  ['Single-Player', 'Steam Achievements', 'Parti...   \n",
       "\n",
       "                                short_description_en  \\\n",
       "0  Counter-Strike: Source blends Counter-Strike's...   \n",
       "1  Niko Bellic, Johnny Klebitz and Luis Lopez all...   \n",
       "2  The Lifetime Test Plan is now upgraded and you...   \n",
       "3  Dig, fight, explore, build! Nothing is impossi...   \n",
       "4  Wasteland Angel is a top-down twin-stick shoot...   \n",
       "\n",
       "                             detailed_description_en  \n",
       "0  THE NEXT INSTALLMENT OF THE WORLD'S # 1 ONLINE...  \n",
       "1  Important Updates To Grand Theft Auto IV and E...  \n",
       "2  Portal 2 creates another successor to the gran...  \n",
       "3  Dig, Fight, Explore, Build: The very world is ...  \n",
       "4  Bummer! World War III happened and killed most...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0a8b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Counter-Strike: Source'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_game_mapper(df):\n",
    "    # Convert the two columns into a dictionary\n",
    "    game_mapper = dict(zip(df['game_appid'], df['game_name']))\n",
    "    return game_mapper\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named 'df' with columns 'game_appid' and 'game_name'\n",
    "game_mapper = create_game_mapper(data)\n",
    "game_mapper[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18db3c5",
   "metadata": {},
   "source": [
    "Feature Embeddings:\n",
    "- Start off with pure genre if it is good enough\n",
    "- (3 approaches) Eval pure genre approach with pure short descriptons embeddings then try combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a3b16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_for_embedding'] = ( data['short_description_en'].fillna('') + ' ' +  data['genres_en'].astype(str) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895decd",
   "metadata": {},
   "source": [
    "Short Description + Genre == Token Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc167c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 472731179\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "for text in data['text_for_embedding']:\n",
    "    word_count+=len(text)\n",
    "print(f'Total number of tokens: {word_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d4276",
   "metadata": {},
   "source": [
    "install transformer of choice (BeRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b41a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(texts, tokenizer, model, max_length=128):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length, padding='max_length')\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # CLS pooling (using [CLS] token embedding)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embedding.squeeze(0))\n",
    "    embeddings = torch.stack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b106cd7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m game_embeddings = \u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext_for_embedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(game_embeddings.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36membed_text\u001b[39m\u001b[34m(texts, tokenizer, model, max_length)\u001b[39m\n\u001b[32m      4\u001b[39m inputs = tokenizer(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, max_length=max_length, padding=\u001b[33m'\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# CLS pooling (using [CLS] token embedding)\u001b[39;00m\n\u001b[32m      8\u001b[39m cls_embedding = outputs.last_hidden_state[:, \u001b[32m0\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1144\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1142\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1156\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1157\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    684\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    685\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    686\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         output_attentions,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    574\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    575\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m    583\u001b[39m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[32m    584\u001b[39m     self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    592\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    594\u001b[39m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    507\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    514\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    525\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:395\u001b[39m, in \u001b[36mBertSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().forward(\n\u001b[32m    384\u001b[39m         hidden_states,\n\u001b[32m    385\u001b[39m         attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m         output_attentions,\n\u001b[32m    391\u001b[39m     )\n\u001b[32m    393\u001b[39m bsz, tgt_len, _ = hidden_states.size()\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m query_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# mask needs to be such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[32m    399\u001b[39m is_cross_attention = encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1539\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1540\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1544\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/deepl/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "game_embeddings = embed_text(data['text_for_embedding'].tolist()[:sample_size], tokenizer, bert_model)\n",
    "print(game_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b870b",
   "metadata": {},
   "source": [
    "## User/Game Node Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad6b1f",
   "metadata": {},
   "source": [
    "### how to dedupe interactions\n",
    "check composite keys (user/game), if all 1s then only unique interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a1125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_playtime_forever\n",
       "1    1996413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=['user_steam_id','game_appid']).count().reset_index()['user_playtime_forever'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c44426",
   "metadata": {},
   "source": [
    "### init mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2e16af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique users and games\n",
    "unique_users = data['user_steam_id'].unique()\n",
    "unique_games = data['game_appid'].unique()\n",
    "\n",
    "# Build mappings\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "game_id_map = {game_id: idx + len(unique_users) for idx, game_id in enumerate(unique_games)}\n",
    "\n",
    "# How many nodes?\n",
    "num_users = len(user_id_map)\n",
    "num_games = len(game_id_map)\n",
    "num_nodes = num_users + num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6647a3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 31397, 37239)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_games, num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64bea2",
   "metadata": {},
   "source": [
    "## Building out user/game nodes\n",
    "- Approximately takes an hour to run, so we will have preloaded from our sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 2000it [00:00, 2269.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# build edges, load a new user to recommend games (edges user to game)\n",
    "user_nodes = []\n",
    "game_nodes = []\n",
    "for idx, row in tqdm(data.iterrows(), desc=\"Processing rows\"):\n",
    "    # get indices and append them\n",
    "    user_idx = user_id_map[row['user_steam_id']]\n",
    "    game_idx = game_id_map[row['game_appid']]\n",
    "    # print(user_idx, game_idx)\n",
    "    user_nodes.append(user_idx)\n",
    "    game_nodes.append(game_idx)\n",
    "    # print(f'User Node {user_idx} and Game Node {game_idx} were appended')\n",
    "    if idx == sample_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4597b6",
   "metadata": {},
   "source": [
    "### Array Dimension Validation\n",
    "- Also upon running initial mapping, storing list in .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbe292a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_nodes)==len(user_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23d48780",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([user_nodes, game_nodes], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7842, 768])\n"
     ]
    }
   ],
   "source": [
    "user_features = np.zeros((num_users, 768))  # dummy features for users\n",
    "game_features = game_embeddings.numpy()      # real features for games\n",
    "\n",
    "# Stack vertically: first users, then games\n",
    "X = np.vstack([user_features, game_features])\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "print(X.shape)  # (num_nodes, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928350ed",
   "metadata": {},
   "source": [
    "## attribute selection for edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7930ad2",
   "metadata": {},
   "source": [
    "if we want more features, add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f58009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 1996413it [00:24, 81540.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1996413, 1])\n"
     ]
    }
   ],
   "source": [
    "edge_attrs = []\n",
    "\n",
    "for idx, row in tqdm(data.iterrows(), desc=\"Processing rows\"):\n",
    "    playtime = row['user_playtime_forever']\n",
    "    edge_attrs.append([playtime])  # wrapping in list for 1-dim feature\n",
    "\n",
    "edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "print(edge_attr.shape)  # (num_edges, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4e6b7",
   "metadata": {},
   "source": [
    "create data for geometric graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97eee5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[7842, 768], edge_index=[2, 2001], edge_y=[1996413, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "graph = Data(\n",
    "    x=X,\n",
    "    edge_index=edge_index,\n",
    "    edge_y=edge_attr\n",
    ")\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5054629",
   "metadata": {},
   "source": [
    "test/train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48162d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[7842, 768], edge_index=[2, 3402], edge_y=[1996413, 1], edge_label=[1701], edge_label_index=[2, 1701])\n",
      "Data(x=[7842, 768], edge_index=[2, 3402], edge_y=[1996413, 1], edge_label=[200], edge_label_index=[2, 200])\n",
      "Data(x=[7842, 768], edge_index=[2, 3602], edge_y=[1996413, 1], edge_label=[400], edge_label_index=[2, 400])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.05,        # 5% for validation\n",
    "    num_test=0.10,       # 10% for testing\n",
    "    is_undirected=True,  # True if your graph is undirected (user <-> game is undirected)\n",
    "    add_negative_train_samples=False  # We will do negative sampling manually during training\n",
    ")\n",
    "\n",
    "# Apply the transform\n",
    "train_data, val_data, test_data = transform(graph)\n",
    "\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df710164",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84a9e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7680bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "    def forward(self, X, edge_index):\n",
    "        X = self.conv1(X, edge_index)\n",
    "        X = F.relu(X)\n",
    "        X = self.conv2(X, edge_index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e740263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(hidden_channels*2, 1)\n",
    "    def forward(self, i, j):\n",
    "        X = torch.cat([i,j], dim=1)\n",
    "        return torch.sigmoid(self.lin(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67408535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "hidden_channels = 128\n",
    "encoder = GNNEncoder(in_channels=graph.num_node_features, hidden_channels=hidden_channels).to(device)\n",
    "predictor = LinkPredictor(hidden_channels=hidden_channels).to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr=0.001)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99ff9239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[7842, 768], edge_index=[2, 3602], edge_y=[1996413, 1], edge_label=[400], edge_label_index=[2, 400])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f550d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    encoder.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "    M = encoder(train_data.x, train_data.edge_index)\n",
    "    preds = predictor(M[train_data.edge_label_index[0]], M[train_data.edge_label_index[1]])\n",
    "    loss = F.binary_cross_entropy(preds.squeeze(), train_data.edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_data):\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "    M = encoder(train_data.x, train_data.edge_index)\n",
    "    preds = predictor(\n",
    "        M[test_data.edge_label_index[0]], \n",
    "        M[test_data.edge_label_index[1]]\n",
    "    )\n",
    "    labels = test_data.edge_label.float()\n",
    "\n",
    "    pred_labels = (preds.squeeze() > 0.5).float()\n",
    "\n",
    "    acc = (pred_labels == labels).sum().item() / labels.size(0)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "faee5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adc39a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 15/50 [00:03<00:05,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.6585, Val Acc: 0.5000\n",
      "Epoch 02, Loss: 0.3596, Val Acc: 0.5000\n",
      "Epoch 03, Loss: 0.1637, Val Acc: 0.5000\n",
      "Epoch 04, Loss: 0.0548, Val Acc: 0.5000\n",
      "Epoch 05, Loss: 0.0145, Val Acc: 0.5000\n",
      "Epoch 06, Loss: 0.0035, Val Acc: 0.5000\n",
      "Epoch 07, Loss: 0.0008, Val Acc: 0.5000\n",
      "Epoch 08, Loss: 0.0002, Val Acc: 0.5000\n",
      "Epoch 09, Loss: 0.0001, Val Acc: 0.5000\n",
      "Epoch 10, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 11, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 12, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 13, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 14, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 15, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 16, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 17, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 18, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 19, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 20, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 21, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 22, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 23, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 24, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 25, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 26, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 27, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 28, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 29, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 30, Loss: 0.0000, Val Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:03<00:00, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 32, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 33, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 34, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 35, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 36, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 37, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 38, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 39, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 40, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 41, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 42, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 43, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 44, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 45, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 46, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 47, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 48, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 49, Loss: 0.0000, Val Acc: 0.5000\n",
      "Epoch 50, Loss: 0.0000, Val Acc: 0.5000\n",
      "\n",
      "Test Accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train()\n",
    "    val_acc = test(val_data)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "test_acc = test(test_data)\n",
    "print(f'\\nTest Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b92eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def recommend_new_games_for_user(user_idx, train_data, top_k=5):\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    # Step 1: Get node embeddings\n",
    "    z = encoder(train_data.x, train_data.edge_index)\n",
    "\n",
    "    user_embeddings = z[:num_users]\n",
    "    game_embeddings = z[num_users:]\n",
    "\n",
    "    user_emb = user_embeddings[user_idx].unsqueeze(0)\n",
    "    user_emb_expanded = user_emb.expand(game_embeddings.size(0), -1)\n",
    "\n",
    "    # Step 2: Predict scores for all games\n",
    "    scores = predictor(user_emb_expanded, game_embeddings).squeeze()\n",
    "\n",
    "    # Step 3: Find already played games\n",
    "    # Find edges where source == user_idx\n",
    "    user_edges = train_data.edge_index[0] == user_idx\n",
    "    played_game_indices = train_data.edge_index[1][user_edges] - num_users  # get game indices\n",
    "\n",
    "    played_game_indices = played_game_indices.tolist()\n",
    "\n",
    "    # Step 4: Mask scores of already played games\n",
    "    scores[played_game_indices] = -1e9  # set played games' scores very low so they won't be selected\n",
    "\n",
    "    # Step 5: Pick top-k games\n",
    "    top_scores, top_game_indices = torch.topk(scores, k=top_k)\n",
    "\n",
    "    recommendations = []\n",
    "    for i, game_idx in enumerate(top_game_indices):\n",
    "        game_id = unique_games[game_idx.item()]  # map back to real game ID\n",
    "        score = top_scores[i].item()\n",
    "        recommendations.append((game_id, score))\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af272d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 new game recommendations for User 0:\n",
      "Rank 1: Game ID = Portal 2, Score = 1.0000\n",
      "Rank 2: Game ID = Path of Exile, Score = 1.0000\n",
      "Rank 3: Game ID = Cubetractor, Score = 1.0000\n",
      "Rank 4: Game ID = The Forest, Score = 1.0000\n",
      "Rank 5: Game ID = Rocket League, Score = 1.0000\n"
     ]
    }
   ],
   "source": [
    "user_idx = 0\n",
    "top_k = 5\n",
    "recommendations = recommend_new_games_for_user(user_idx=user_idx, train_data=train_data, top_k=top_k)\n",
    "\n",
    "print(f\"\\nTop {top_k} new game recommendations for User {user_idx}:\")\n",
    "for rank, (game_id, score) in enumerate(recommendations, start=1):\n",
    "    print(f\"Rank {rank}: Game ID = {game_mapper[game_id]}, Score = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "38a5d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import to_networkx\n",
    "# import networkx as nx\n",
    "\n",
    "# # Convert to NetworkX graph\n",
    "# G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# pos = nx.spring_layout(G, seed=42)  # spring layout (force-directed)\n",
    "\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     node_size=10, \n",
    "#     edge_color=\"gray\", \n",
    "#     alpha=0.7,\n",
    "#     node_color=\"blue\"\n",
    "# )\n",
    "# plt.title(\"User-Game Bipartite Graph Visualization\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dce9c1",
   "metadata": {},
   "source": [
    "Actionable Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c98a7b",
   "metadata": {},
   "source": [
    "# Cold Start Recommendation if the user is not in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a710d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f30eca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "STEAM_API_KEY = os.getenv(\"STEAM_API_KEY\")\n",
    "\n",
    "# ðŸ‘‡ Build this once when you load your graph\n",
    "game_idx_map = {appid: idx for idx, appid in enumerate(unique_games)}\n",
    "\n",
    "@torch.no_grad()\n",
    "def recommend_games_by_steam_id(steam_id, user_id_map, train_data, top_k=5):\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    z = encoder(train_data.x, train_data.edge_index)\n",
    "\n",
    "    user_embeddings = z[:num_users]\n",
    "    game_embeddings = z[num_users:]\n",
    "\n",
    "    if steam_id in user_id_map:\n",
    "        print(f\"Steam ID {steam_id} found in graph âœ…\")\n",
    "        user_idx = user_id_map[steam_id]\n",
    "        user_emb = user_embeddings[user_idx].unsqueeze(0)\n",
    "    else:\n",
    "        print(f\"Steam ID {steam_id} not found. Trying Steam API cold-start fallback...\")\n",
    "\n",
    "        owned_game_ids = get_owned_games_from_steam(steam_id)\n",
    "        if not owned_game_ids:\n",
    "            print(f\"No games found for Steam ID {steam_id} Cannot recommend.\")\n",
    "            return []\n",
    "\n",
    "        known_owned_games = [appid for appid in owned_game_ids if appid in unique_games]\n",
    "        if not known_owned_games:\n",
    "            print(f\"No known games found for Steam ID {steam_id} Cannot recommend.\")\n",
    "            return []\n",
    "\n",
    "        game_idxs = [game_id_map[appid] - num_users for appid in known_owned_games]\n",
    "        user_emb = game_embeddings[game_idxs].mean(dim=0).unsqueeze(0)\n",
    "        print(f\"Created cold-start embedding from {len(game_idxs)} owned games\")\n",
    "\n",
    "    user_emb_expanded = user_emb.expand(game_embeddings.size(0), -1)\n",
    "    scores = predictor(user_emb_expanded, game_embeddings).squeeze()\n",
    "\n",
    "    if steam_id in user_id_map:\n",
    "        user_idx = user_id_map[steam_id]\n",
    "        user_edges = train_data.edge_index[0] == user_idx\n",
    "        played_game_indices = train_data.edge_index[1][user_edges] - num_users\n",
    "        played_game_indices = played_game_indices.tolist()\n",
    "        scores[played_game_indices] = -1e9\n",
    "    else:\n",
    "        played_game_indices = [game_idx_map[appid] for appid in known_owned_games if appid in game_idx_map]\n",
    "        scores[played_game_indices] = -1e9\n",
    "\n",
    "    top_scores, top_game_indices = torch.topk(scores, k=top_k)\n",
    "\n",
    "    recommendations = []\n",
    "    for i, game_idx in enumerate(top_game_indices):\n",
    "        game_id = unique_games[game_idx.item()]\n",
    "        score = top_scores[i].item()\n",
    "        recommendations.append((game_id, score))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# --- Helper ---\n",
    "def get_owned_games_from_steam(steam_id):\n",
    "    url = \"http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/\"\n",
    "    params = {\n",
    "        'key': STEAM_API_KEY,\n",
    "        'steamid': steam_id,\n",
    "        'format': 'json',\n",
    "        'include_appinfo': False,\n",
    "        'include_played_free_games': True\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        data = response.json()\n",
    "\n",
    "        if 'response' in data and 'games' in data['response']:\n",
    "            games = data['response']['games']\n",
    "            owned_game_ids = [game['appid'] for game in games]\n",
    "            return owned_game_ids\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching games for Steam ID {steam_id}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6856771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steam ID 76561198030330010 not found. Trying Steam API cold-start fallback...\n",
      "Created cold-start embedding from 1206 owned games âœ…\n",
      "\n",
      "Top 5 recommendations for Steam ID 76561198030330010:\n",
      "Rank 1: Wasteland Angel (Score: 1.0000)\n",
      "Rank 2: TrackMania Nations Forever (Score: 1.0000)\n",
      "Rank 3: Path of Exile (Score: 1.0000)\n",
      "Rank 4: Batman: Arkham Origins (Score: 1.0000)\n",
      "Rank 5: Trove (Score: 1.0000)\n",
      "Rank 6: Unturned (Score: 1.0000)\n",
      "Rank 7: Heroes & Generals (Score: 1.0000)\n",
      "Rank 8: DRAGON BALL XENOVERSE (Score: 1.0000)\n",
      "Rank 9: Batman: Arkham Knight (Score: 1.0000)\n",
      "Rank 10: VRChat (Score: 1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Before: Build mapping once\n",
    "appid_to_game_name = dict(zip(data['game_appid'], data['game_name']))\n",
    "\n",
    "# Recommend\n",
    "steam_id = 76561198030330010\n",
    "recommendations = recommend_games_by_steam_id(steam_id, user_id_map, train_data, top_k=10)\n",
    "\n",
    "# Print results nicely\n",
    "print(f\"\\nTop 5 recommendations for Steam ID {steam_id}:\")\n",
    "for rank, (game_id, score) in enumerate(recommendations, start=1):\n",
    "    game_name = appid_to_game_name.get(game_id, f\"Unknown Game ({game_id})\")\n",
    "    print(f\"Rank {rank}: {game_name} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583a92b",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
