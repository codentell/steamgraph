{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765e03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eebcf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = os.environ[\"STEAM_API_KEY\"]  # Raises a KeyError if the variable isn't set\n",
    "full_size = 1996413\n",
    "sample_size = int(1 * full_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfb155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained BERT-base\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Move the model to GPU\n",
    "bert_model.to(device)\n",
    "bert_model.eval()  # Evaluation mode (no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a992ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_fantasy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d8a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996413, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a8b5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Counter-Strike: Source'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_game_mapper(df):\n",
    "    # Convert the two columns into a dictionary\n",
    "    game_mapper = dict(zip(df['game_appid'], df['game_name']))\n",
    "    return game_mapper\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a DataFrame named 'df' with columns 'game_appid' and 'game_name'\n",
    "game_mapper = create_game_mapper(data)\n",
    "game_mapper[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18db3c5",
   "metadata": {},
   "source": [
    "Feature Embeddings:\n",
    "- Start off with pure genre if it is good enough\n",
    "- (3 approaches) Eval pure genre approach with pure short descriptons embeddings then try combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46caf3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'user_steam_id', 'user_playtime_forever',\n",
       "       'user_playtime_2weeks', 'user_has_leaderboards',\n",
       "       'user_has_community_visible_stats', 'user_content_descriptorids',\n",
       "       'game_appid', 'game_name', 'game_developer', 'game_publisher',\n",
       "       'game_price', 'game_initialprice', 'game_discount', 'game_ccu',\n",
       "       'game_owners_estimate', 'game_review_ratio', 'genres_en',\n",
       "       'categories_en', 'short_description_en', 'detailed_description_en'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3b16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['text_for_embedding'] = ( data['short_description_en'].fillna('') + ' ' +  data['genres_en'].astype(str) )\n",
    "# data['full_description_embedding'] = ( data['short_description_en'].fillna('') + ' ' +  data['detailed_description_en'].fillna('') )\n",
    "data['full_description_embedding'] = data.apply(lambda row: f\"{row['short_description_en']} {row['detailed_description_en']} {row['genres_en']} {row['categories_en']}\" if pd.notna(row['detailed_description_en']) else row['short_description_en'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895decd",
   "metadata": {},
   "source": [
    "Short Description + Genre == Token Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc167c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 4319879969\n"
     ]
    }
   ],
   "source": [
    "# word_count = 0\n",
    "# for text in data['text_for_embedding']:\n",
    "#     word_count+=len(text)\n",
    "# print(f'Total number of tokens: {word_count}')\n",
    "data['full_description_embedding'] = data['full_description_embedding'].fillna('')\n",
    "word_count = 0\n",
    "for text in data['full_description_embedding']:\n",
    "    word_count+=len(text)\n",
    "print(f'Total number of tokens: {word_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d4276",
   "metadata": {},
   "source": [
    "install transformer of choice (BeRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b41a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(texts, tokenizer, model, batch_size=16, max_length=512):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, max_length=max_length, padding=True)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(cls_embeddings)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1920eeb9",
   "metadata": {},
   "source": [
    "I have the embeddings done separately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b106cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "# game_embeddings = embed_text(data['full_description_embedding'].tolist()[:sample_size], tokenizer, bert_model)\n",
    "# print(game_embeddings.shape)\n",
    "# torch.save(game_embeddings, \"game_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b870b",
   "metadata": {},
   "source": [
    "## User/Game Node Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad6b1f",
   "metadata": {},
   "source": [
    "### how to dedupe interactions\n",
    "check composite keys (user/game), if all 1s then only unique interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41a1125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_playtime_forever\n",
       "1    1996413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=['user_steam_id','game_appid']).count().reset_index()['user_playtime_forever'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c44426",
   "metadata": {},
   "source": [
    "### init mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2e16af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique users and games\n",
    "unique_users = data['user_steam_id'].unique()\n",
    "unique_games = data['game_appid'].unique()\n",
    "\n",
    "# Build mappings\n",
    "user_id_map = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "game_id_map = {game_id: idx + len(unique_users) for idx, game_id in enumerate(unique_games)}\n",
    "\n",
    "# How many nodes?\n",
    "num_users = len(user_id_map)\n",
    "num_games = len(game_id_map)\n",
    "num_nodes = num_users + num_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6647a3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 31397, 37239)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_games, num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a64bea2",
   "metadata": {},
   "source": [
    "## Building out user/game nodes\n",
    "- Approximately takes an hour to run, so we will have preloaded from our sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622c323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 1996413it [01:47, 18538.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# build edges, load a new user to recommend games (edges user to game)\n",
    "user_nodes = []\n",
    "game_nodes = []\n",
    "for idx, row in tqdm(data.iterrows(), desc=\"Processing rows\"):\n",
    "    # get indices and append them\n",
    "    user_idx = user_id_map[row['user_steam_id']]\n",
    "    game_idx = game_id_map[row['game_appid']]\n",
    "    # print(user_idx, game_idx)\n",
    "    user_nodes.append(user_idx)\n",
    "    game_nodes.append(game_idx)\n",
    "    # print(f'User Node {user_idx} and Game Node {game_idx} were appended')\n",
    "    if idx == sample_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4597b6",
   "metadata": {},
   "source": [
    "### Array Dimension Validation\n",
    "- Also upon running initial mapping, storing list in .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23d48780",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([user_nodes, game_nodes], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e160d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2002255, 768])\n"
     ]
    }
   ],
   "source": [
    "user_features = np.zeros((num_users, 768))  # dummy features for users\n",
    "# game_features = game_embeddings.numpy()      # real features for games\n",
    "# game_features = game_embeddings.cpu().numpy()      # For Cuda\n",
    "game_features = torch.load(\"game_embeddings.pt\").to('cpu') # This line of code takes 1.2 minutes roughly\n",
    "\n",
    "# Stack vertically: first users, then games\n",
    "X = np.vstack([user_features, game_features])\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "print(X.shape)  # (num_nodes, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928350ed",
   "metadata": {},
   "source": [
    "## attribute selection for edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7930ad2",
   "metadata": {},
   "source": [
    "if we want more features, add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f58009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 1996413it [00:27, 73871.72it/s] \n"
     ]
    }
   ],
   "source": [
    "# edge_attrs = []\n",
    "\n",
    "# for idx, row in tqdm(data.iterrows(), desc=\"Processing rows\"):\n",
    "#     playtime = row['user_playtime_forever']\n",
    "#     edge_attrs.append([playtime])  # wrapping in list for 1-dim feature\n",
    "\n",
    "# edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "# print(edge_attr.shape)  # (num_edges, 1)\n",
    "edge_attrs = [] # Roughly 1 minute\n",
    "for row in tqdm(data.itertuples(index=False), desc=\"Processing rows\"):\n",
    "    playtime = row.user_playtime_forever\n",
    "    played_games = row.game_appid\n",
    "    \n",
    "    edge_attrs.append([playtime, played_games])  # Wrapping in list for 1D feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4e6b7",
   "metadata": {},
   "source": [
    "create data for geometric graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97eee5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2002255, 768], edge_index=[2, 1996413], edge_y=[1996413, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "\n",
    "graph = Data(\n",
    "    x=X,\n",
    "    edge_index=edge_index,\n",
    "    edge_y=edge_attr\n",
    ")\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5054629",
   "metadata": {},
   "source": [
    "test/train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48162d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2002255, 768], edge_index=[2, 3393904], edge_y=[3393904, 2], edge_label=[1696952], edge_label_index=[2, 1696952])\n",
      "Data(x=[2002255, 768], edge_index=[2, 3393904], edge_y=[3393904, 2], edge_label=[199640], edge_label_index=[2, 199640])\n",
      "Data(x=[2002255, 768], edge_index=[2, 3593544], edge_y=[3593544, 2], edge_label=[399282], edge_label_index=[2, 399282])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.05,        # 5% for validation\n",
    "    num_test=0.10,       # 10% for testing\n",
    "    is_undirected=True,  # True if your graph is undirected (user <-> game is undirected)\n",
    "    add_negative_train_samples=False  # We will do negative sampling manually during training\n",
    ")\n",
    "\n",
    "# Apply the transform\n",
    "train_data, val_data, test_data = transform(graph)\n",
    "\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df710164",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84a9e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7680bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "    def forward(self, X, edge_index):\n",
    "        X = self.conv1(X, edge_index)\n",
    "        X = F.relu(X)\n",
    "        X = self.conv2(X, edge_index)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e740263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(hidden_channels*2, 1)\n",
    "    def forward(self, i, j):\n",
    "        X = torch.cat([i,j], dim=1)\n",
    "        return torch.sigmoid(self.lin(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67408535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "hidden_channels = 128\n",
    "encoder = GNNEncoder(in_channels=graph.num_node_features, hidden_channels=hidden_channels).to(device)\n",
    "predictor = LinkPredictor(hidden_channels=hidden_channels).to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(predictor.parameters()), lr=0.001)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99ff9239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2002255, 768], edge_index=[2, 3593544], edge_y=[3593544, 2], edge_label=[399282], edge_label_index=[2, 399282])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f550d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    encoder.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "    M = encoder(train_data.x, train_data.edge_index)\n",
    "    preds = predictor(M[train_data.edge_label_index[0]], M[train_data.edge_label_index[1]])\n",
    "    loss = F.binary_cross_entropy(preds.squeeze(), train_data.edge_label.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(test_data):\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "    M = encoder(train_data.x, train_data.edge_index)\n",
    "    preds = predictor(\n",
    "        M[test_data.edge_label_index[0]], \n",
    "        M[test_data.edge_label_index[1]]\n",
    "    )\n",
    "    labels = test_data.edge_label.float()\n",
    "\n",
    "    pred_labels = (preds.squeeze() > 0.5).float()\n",
    "\n",
    "    acc = (pred_labels == labels).sum().item() / labels.size(0)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faee5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc39a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 9.71 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(val_data)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m predictor\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 5\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m preds \u001b[38;5;241m=\u001b[39m predictor(M[train_data\u001b[38;5;241m.\u001b[39medge_label_index[\u001b[38;5;241m0\u001b[39m]], M[train_data\u001b[38;5;241m.\u001b[39medge_label_index[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(preds\u001b[38;5;241m.\u001b[39msqueeze(), train_data\u001b[38;5;241m.\u001b[39medge_label\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m, in \u001b[0;36mGNNEncoder.forward\u001b[1;34m(self, X, edge_index)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, edge_index):\n\u001b[1;32m----> 7\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     X \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(X)\n\u001b[0;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(X, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[1;34m(self, x, edge_index, size)\u001b[0m\n\u001b[0;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[0;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_1gk8mu6h.py:173\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m    167\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    168\u001b[0m         out,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_1gk8mu6h.py:83\u001b[0m, in \u001b[0;36mcollect\u001b[1;34m(self, edge_index, x, size)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[1;32m---> 83\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:290\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound indices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m that are larger \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour node feature matrix and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 290\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.71 GiB. GPU "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    loss = train()\n",
    "    val_acc = test(val_data)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "test_acc = test(test_data)\n",
    "print(f'\\nTest Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def recommend_new_games_for_user(user_idx, train_data, top_k=5):\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    # Step 1: Get node embeddings\n",
    "    z = encoder(train_data.x, train_data.edge_index)\n",
    "\n",
    "    user_embeddings = z[:num_users]\n",
    "    game_embeddings = z[num_users:]\n",
    "\n",
    "    user_emb = user_embeddings[user_idx].unsqueeze(0)\n",
    "    user_emb_expanded = user_emb.expand(game_embeddings.size(0), -1)\n",
    "\n",
    "    # Step 2: Predict scores for all games\n",
    "    scores = predictor(user_emb_expanded, game_embeddings).squeeze()\n",
    "\n",
    "    # Step 3: Find already played games\n",
    "    # Find edges where source == user_idx\n",
    "    user_edges = train_data.edge_index[0] == user_idx\n",
    "    played_game_indices = train_data.edge_index[1][user_edges] - num_users  # get game indices\n",
    "\n",
    "    played_game_indices = played_game_indices.tolist()\n",
    "\n",
    "    # Step 4: Mask scores of already played games\n",
    "    scores[played_game_indices] = -1e9  # set played games' scores very low so they won't be selected\n",
    "\n",
    "    # Step 5: Pick top-k games\n",
    "    top_scores, top_game_indices = torch.topk(scores, k=top_k)\n",
    "\n",
    "    recommendations = []\n",
    "    for i, game_idx in enumerate(top_game_indices):\n",
    "        game_id = unique_games[game_idx.item()]  # map back to real game ID\n",
    "        score = top_scores[i].item()\n",
    "        recommendations.append((game_id, score))\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af272d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 new game recommendations for User 999:\n",
      "Rank 1: Game ID = Ranch Simulator: Build, Hunt, Farm, Score = 0.9994\n",
      "Rank 2: Game ID = VRocker, Score = 0.9994\n",
      "Rank 3: Game ID = Tormentum - Dark Sorrow, Score = 0.9994\n",
      "Rank 4: Game ID = Mytheon, Score = 0.9994\n",
      "Rank 5: Game ID = Gravity Cat, Score = 0.9994\n",
      "Rank 6: Game ID = Lost in Spice, Score = 0.9994\n",
      "Rank 7: Game ID = Gray Skies, Dark Waters, Score = 0.9994\n",
      "Rank 8: Game ID = Acorns Above: A World Gone Nuts, Score = 0.9994\n",
      "Rank 9: Game ID = Aero GPX, Score = 0.9994\n",
      "Rank 10: Game ID = EverQuest II, Score = 0.9994\n"
     ]
    }
   ],
   "source": [
    "user_idx = 999\n",
    "top_k = 10\n",
    "recommendations = recommend_new_games_for_user(user_idx=user_idx, train_data=train_data, top_k=top_k)\n",
    "\n",
    "print(f\"\\nTop {top_k} new game recommendations for User {user_idx}:\")\n",
    "for rank, (game_id, score) in enumerate(recommendations, start=1):\n",
    "    print(f\"Rank {rank}: Game ID = {game_mapper[game_id]}, Score = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import to_networkx\n",
    "# import networkx as nx\n",
    "\n",
    "# # Convert to NetworkX graph\n",
    "# G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# pos = nx.spring_layout(G, seed=42)  # spring layout (force-directed)\n",
    "\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     node_size=10, \n",
    "#     edge_color=\"gray\", \n",
    "#     alpha=0.7,\n",
    "#     node_color=\"blue\"\n",
    "# )\n",
    "# plt.title(\"User-Game Bipartite Graph Visualization\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dce9c1",
   "metadata": {},
   "source": [
    "Actionable Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c98a7b",
   "metadata": {},
   "source": [
    "# Cold Start Recommendation if the user is not in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a710d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30eca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "STEAM_API_KEY = os.getenv(\"STEAM_API_KEY\")\n",
    "\n",
    "# 👇 Build this once when you load your graph\n",
    "game_idx_map = {appid: idx for idx, appid in enumerate(unique_games)}\n",
    "\n",
    "@torch.no_grad()\n",
    "def recommend_games_by_steam_id(steam_id, user_id_map, train_data, top_k=5):\n",
    "    encoder.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    z = encoder(train_data.x, train_data.edge_index)\n",
    "\n",
    "    user_embeddings = z[:num_users]\n",
    "    game_embeddings = z[num_users:]\n",
    "\n",
    "    if steam_id in user_id_map:\n",
    "        print(f\"Steam ID {steam_id} found in graph ✅\")\n",
    "        user_idx = user_id_map[steam_id]\n",
    "        user_emb = user_embeddings[user_idx].unsqueeze(0)\n",
    "    else:\n",
    "        print(f\"Steam ID {steam_id} not found. Trying Steam API cold-start fallback...\")\n",
    "\n",
    "        owned_game_ids = get_owned_games_from_steam(steam_id)\n",
    "        if not owned_game_ids:\n",
    "            print(f\"No games found for Steam ID {steam_id} Cannot recommend.\")\n",
    "            return []\n",
    "\n",
    "        known_owned_games = [appid for appid in owned_game_ids if appid in unique_games]\n",
    "        if not known_owned_games:\n",
    "            print(f\"No known games found for Steam ID {steam_id} Cannot recommend.\")\n",
    "            return []\n",
    "\n",
    "        game_idxs = [game_id_map[appid] - num_users for appid in known_owned_games]\n",
    "        user_emb = game_embeddings[game_idxs].mean(dim=0).unsqueeze(0)\n",
    "        print(f\"Created cold-start embedding from {len(game_idxs)} owned games\")\n",
    "\n",
    "    user_emb_expanded = user_emb.expand(game_embeddings.size(0), -1)\n",
    "    scores = predictor(user_emb_expanded, game_embeddings).squeeze()\n",
    "\n",
    "    if steam_id in user_id_map:\n",
    "        user_idx = user_id_map[steam_id]\n",
    "        user_edges = train_data.edge_index[0] == user_idx\n",
    "        played_game_indices = train_data.edge_index[1][user_edges] - num_users\n",
    "        played_game_indices = played_game_indices.tolist()\n",
    "        scores[played_game_indices] = -1e9\n",
    "    else:\n",
    "        played_game_indices = [game_idx_map[appid] for appid in known_owned_games if appid in game_idx_map]\n",
    "        scores[played_game_indices] = -1e9\n",
    "\n",
    "    top_scores, top_game_indices = torch.topk(scores, k=top_k)\n",
    "\n",
    "    recommendations = []\n",
    "    for i, game_idx in enumerate(top_game_indices):\n",
    "        game_id = unique_games[game_idx.item()]\n",
    "        score = top_scores[i].item()\n",
    "        recommendations.append((game_id, score))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# --- Helper ---\n",
    "def get_owned_games_from_steam(steam_id):\n",
    "    url = \"http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/\"\n",
    "    params = {\n",
    "        'key': STEAM_API_KEY,\n",
    "        'steamid': steam_id,\n",
    "        'format': 'json',\n",
    "        'include_appinfo': False,\n",
    "        'include_played_free_games': True\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        data = response.json()\n",
    "\n",
    "        if 'response' in data and 'games' in data['response']:\n",
    "            games = data['response']['games']\n",
    "            owned_game_ids = [game['appid'] for game in games]\n",
    "            return owned_game_ids\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching games for Steam ID {steam_id}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steam ID 76561199383582027 found in graph ✅\n",
      "\n",
      "Top 5 recommendations for Steam ID 76561199383582027:\n",
      "Rank 1: Ranch Simulator: Build, Hunt, Farm (Score: 0.9994)\n",
      "Rank 2: VRocker (Score: 0.9994)\n",
      "Rank 3: Tormentum - Dark Sorrow (Score: 0.9994)\n",
      "Rank 4: Mytheon (Score: 0.9994)\n",
      "Rank 5: Gravity Cat (Score: 0.9994)\n",
      "Rank 6: Lost in Spice (Score: 0.9994)\n",
      "Rank 7: Gray Skies, Dark Waters (Score: 0.9994)\n",
      "Rank 8: Acorns Above: A World Gone Nuts (Score: 0.9994)\n",
      "Rank 9: Aero GPX (Score: 0.9994)\n",
      "Rank 10: EverQuest II (Score: 0.9994)\n"
     ]
    }
   ],
   "source": [
    "# Before: Build mapping once\n",
    "appid_to_game_name = dict(zip(data['game_appid'], data['game_name']))\n",
    "# Recommend\n",
    "# https://steamcommunity.com/profiles/76561198005754455/\n",
    "steam_id = 76561199383582027\n",
    "recommendations = recommend_games_by_steam_id(steam_id, user_id_map, train_data, top_k=10)\n",
    "\n",
    "# Print results nicely\n",
    "print(f\"\\nTop 5 recommendations for Steam ID {steam_id}:\")\n",
    "for rank, (game_id, score) in enumerate(recommendations, start=1):\n",
    "    game_name = appid_to_game_name.get(game_id, f\"Unknown Game ({game_id})\")\n",
    "    print(f\"Rank {rank}: {game_name} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583a92b",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
