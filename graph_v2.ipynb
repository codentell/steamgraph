{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d93b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, NNConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "data = pd.read_csv('final_fantasy.csv')\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Change cpu to mps for Mac\n",
    "# device = torch.device(\"cpu\")  # Move computation to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_steam_id</th>\n",
       "      <th>game_appid</th>\n",
       "      <th>genres_en</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>user_playtime_forever</th>\n",
       "      <th>user_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>genre_ids</th>\n",
       "      <th>category_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>240</td>\n",
       "      <td>['Action']</td>\n",
       "      <td>['Multi-Player', 'Cross-Platform Multiplayer',...</td>\n",
       "      <td>7279</td>\n",
       "      <td>2553</td>\n",
       "      <td>10</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>12210</td>\n",
       "      <td>['Action', 'Adventure']</td>\n",
       "      <td>['Single-Player', 'Multi-Player', 'Partial Con...</td>\n",
       "      <td>0</td>\n",
       "      <td>2553</td>\n",
       "      <td>333</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[8, 0, 9, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>620</td>\n",
       "      <td>['Action', 'Adventure']</td>\n",
       "      <td>['Single Person', 'Multiple People', 'Cooperat...</td>\n",
       "      <td>717</td>\n",
       "      <td>2553</td>\n",
       "      <td>18</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[12, 13, 14, 15, 16, 17, 2, 18, 19, 20, 21, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>105600</td>\n",
       "      <td>['Action', 'Adventure', 'Indie', 'Rpg']</td>\n",
       "      <td>['Single-Player', 'Multi-Player', 'Pvp', 'Onli...</td>\n",
       "      <td>4578</td>\n",
       "      <td>2553</td>\n",
       "      <td>1248</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>[8, 0, 29, 30, 31, 32, 2, 33, 34, 3, 10, 11, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198060785055</td>\n",
       "      <td>46520</td>\n",
       "      <td>['Action', 'Indie']</td>\n",
       "      <td>['Single-Player', 'Steam Achievements', 'Parti...</td>\n",
       "      <td>0</td>\n",
       "      <td>2553</td>\n",
       "      <td>956</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[8, 2, 9, 36, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_steam_id  game_appid                                genres_en  \\\n",
       "0  76561198060785055         240                               ['Action']   \n",
       "1  76561198060785055       12210                  ['Action', 'Adventure']   \n",
       "2  76561198060785055         620                  ['Action', 'Adventure']   \n",
       "3  76561198060785055      105600  ['Action', 'Adventure', 'Indie', 'Rpg']   \n",
       "4  76561198060785055       46520                      ['Action', 'Indie']   \n",
       "\n",
       "                                       categories_en  user_playtime_forever  \\\n",
       "0  ['Multi-Player', 'Cross-Platform Multiplayer',...                   7279   \n",
       "1  ['Single-Player', 'Multi-Player', 'Partial Con...                      0   \n",
       "2  ['Single Person', 'Multiple People', 'Cooperat...                    717   \n",
       "3  ['Single-Player', 'Multi-Player', 'Pvp', 'Onli...                   4578   \n",
       "4  ['Single-Player', 'Steam Achievements', 'Parti...                      0   \n",
       "\n",
       "   user_id  game_id     genre_ids  \\\n",
       "0     2553       10           [0]   \n",
       "1     2553      333        [0, 1]   \n",
       "2     2553       18        [0, 1]   \n",
       "3     2553     1248  [0, 1, 2, 3]   \n",
       "4     2553      956        [0, 2]   \n",
       "\n",
       "                                        category_ids  \n",
       "0                           [0, 1, 2, 3, 4, 5, 6, 7]  \n",
       "1                                  [8, 0, 9, 10, 11]  \n",
       "2  [12, 13, 14, 15, 16, 17, 2, 18, 19, 20, 21, 21...  \n",
       "3  [8, 0, 29, 30, 31, 32, 2, 33, 34, 3, 10, 11, 3...  \n",
       "4                                   [8, 2, 9, 36, 7]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding data\n",
    "user_encoder, game_encoder, genre_encoder, category_encoder = LabelEncoder(), LabelEncoder(), LabelEncoder(), LabelEncoder()\n",
    "full_data = data.shape[0]\n",
    "percent_data = .25\n",
    "num_entries = int(full_data * percent_data) # Number of entries to use\n",
    "\n",
    "smaller_df = data[:num_entries]\n",
    "smaller_df = smaller_df[['user_steam_id', 'game_appid', 'genres_en', 'categories_en', 'user_playtime_forever']]\n",
    "smaller_df['user_id'] = user_encoder.fit_transform(smaller_df['user_steam_id'])\n",
    "smaller_df['game_id'] = game_encoder.fit_transform(smaller_df['game_appid'])\n",
    "\n",
    "genre_map = dict()\n",
    "for genres in data['genres_en']:\n",
    "    if genres == 'Nan':\n",
    "        continue\n",
    "    for genre in eval(genres):\n",
    "        if genre not in genre_map:\n",
    "            genre_map[genre] = len(genre_map)\n",
    "\n",
    "def genre_mapper(row):\n",
    "    if row == 'Nan':\n",
    "        return []\n",
    "    row = eval(row)\n",
    "    formatted_row = [genre_map[item] for item in row]\n",
    "    return formatted_row\n",
    "\n",
    "smaller_df['genre_ids'] = smaller_df['genres_en'].apply(genre_mapper).copy()\n",
    "\n",
    "category_map = dict()\n",
    "for categories in data['categories_en']:\n",
    "    if categories == 'Nan':\n",
    "        continue\n",
    "    categories = categories.replace('s\\' ', 's') # Screw you 'Players' Battles'\n",
    "    for category in eval(categories):\n",
    "        if category not in category_map:\n",
    "            category_map[category] = len(category_map)\n",
    "\n",
    "def category_mapper(row):\n",
    "    if row == 'Nan':\n",
    "        return []\n",
    "    row = eval(row)\n",
    "    formatted_row = [category_map[item] for item in row]\n",
    "    return formatted_row\n",
    "\n",
    "smaller_df['categories_en'] = smaller_df['categories_en'].apply(lambda x: x.replace('s\\' ', 's'))\n",
    "smaller_df['category_ids'] = smaller_df['categories_en'].apply(category_mapper).copy()\n",
    "smaller_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1dee609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anima\\AppData\\Local\\Temp\\ipykernel_28944\\1063651911.py:4: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  h_data['user'].x = torch.arange(len(user_encoder.classes_)).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Setting up HeteroData\n",
    "\n",
    "h_data = HeteroData() # The h is for hentai\n",
    "h_data['user'].x = torch.arange(len(user_encoder.classes_)).to(device)\n",
    "h_data['game'].x = torch.arange(len(game_encoder.classes_)).to(device)\n",
    "h_data['genre'].x = torch.arange(len(genre_map)).to(device)\n",
    "h_data['category'].x = torch.arange(len(category_map)).to(device)\n",
    "h_data = h_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Genres\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "def embed_texts(texts, batch_size=32, save_every_n_batches=100, checkpoint_path=None, batches_completed=0):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    name = texts.name\n",
    "    texts = texts.tolist()\n",
    "\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        all_embeddings = torch.cat(torch.load(checkpoint_path), dim=0).to(device)\n",
    "        print(f\"Loaded checkpoint from {checkpoint_path} with {len(all_embeddings)} batches.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(total=len(texts) // batch_size, desc=f\"Embedding {name}\", unit=\"batch\")\n",
    "        \n",
    "        for i in range(batches_completed * batch_size, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}  # Move to GPU\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :].to(device)\n",
    "            all_embeddings.append(cls_embeddings)\n",
    "\n",
    "            torch.cuda.empty_cache()  # Free up GPU memory\n",
    "            progress_bar.update(1)\n",
    "\n",
    "            if (i // batch_size) % save_every_n_batches == 0:\n",
    "                torch.save(all_embeddings, f\"{name}_embeddings.pth\")\n",
    "                tqdm.write(f\"💾 Checkpoint saved after {i // batch_size} batches.\")\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    torch.save(all_embeddings, f\"{name}_embeddings.pth\")\n",
    "    print(\"🎉 Embeddings saved successfully!\")\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# genre_embeddings = embed_genre_texts(smaller_df['genres_en'].tolist(), batch_size = 4)  # [num_rows, 768]\n",
    "# projector = torch.nn.Linear(768, 64).to(device)\n",
    "# genre_embeddings_projected = projector(genre_embeddings)  # [num_rows, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/Load genre_embeddings\n",
    "# torch.save(genre_embeddings_projected, \"genre_en_embeddings.pth\")\n",
    "genre_embeddings_projected = torch.cat(torch.load(\"genres_en_embeddings.pth\"), dim=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5043147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run category embeddings and save/load them\n",
    "# category_embeddings = embed_texts(smaller_df['categories_en'], 100, checkpoint_path=\"categories_en_embeddings.pth\", batches_completed=39901)\n",
    "# projector = torch.nn.Linear(768, 64).to(device)\n",
    "# category_embeddings_projected = projector(category_embeddings)\n",
    "# torch.save(category_embeddings_projected, \"categories_en_embeddings.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8f323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing playtime because some loser has 81k hours in a game\n",
    "playtime = torch.tensor(smaller_df['user_playtime_forever'].values, dtype=torch.float).to(device)\n",
    "playtime_norm = (playtime - playtime.min()) / (playtime.max() - playtime.min() + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e824d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anima\\AppData\\Local\\Temp\\ipykernel_28944\\2967143548.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  user_game_edges = torch.tensor([\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[   10,    10,    10,  ..., 14727, 14727, 14727],\n",
       "        [    0,     1,     2,  ...,    10,    11,     7]], device='cuda:0')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up indexes and attributes for h_data\n",
    "user_game_edges = torch.tensor(np.array([\n",
    "    smaller_df['user_id'].values,\n",
    "    smaller_df['game_id'].values\n",
    "]), dtype=torch.long)\n",
    "h_data['user', 'plays', 'game'].edge_index = user_game_edges \n",
    "h_data['user', 'plays', 'game'].edge_attr = playtime_norm\n",
    "\n",
    "# game → genre\n",
    "game_genre_pairs = [(row['game_id'], genre_id) for _, row in smaller_df.iterrows()\n",
    "    for genre_id in row['genre_ids']\n",
    "]\n",
    "game_genre_edges = torch.tensor(game_genre_pairs, dtype=torch.long).t().to(device)\n",
    "h_data['game', 'has_genre', 'genre'].edge_index = game_genre_edges\n",
    "\n",
    "# edge_index[1] gives genre_id for each edge\n",
    "genre_ids_per_edge = game_genre_edges[1]  # shape: [2811]\n",
    "\n",
    "# Pick the embedding for each genre node involved in each edge\n",
    "h_data['game', 'has_genre', 'genre'].edge_attr = genre_embeddings_projected[genre_ids_per_edge]\n",
    "\n",
    "# game → category\n",
    "# game_cat_pairs = [\n",
    "#     (row['game_id'], cat_id)\n",
    "#     for _, row in smaller_df.iterrows()\n",
    "#     for cat_id in row['category_ids']\n",
    "# ]\n",
    "# game_cat_edges = torch.tensor(game_cat_pairs, dtype=torch.long).t().to(device)\n",
    "# h_data['game', 'has_category', 'category'].edge_index = game_cat_edges\n",
    "# h_data['game', 'has_category', 'category']\n",
    "\n",
    "# Do the same thing for categories\n",
    "game_category_pairs = [(row['category_ids'], category_id) for _, row in smaller_df.itterown() \n",
    "    for category_id in row['category_ids']\n",
    "]\n",
    "game_category_edges = torch.tensor(game_category_pairs, dtype=torch.long).t().to(device)\n",
    "h_data['game', 'has_category', 'category'].edge_index = game_category_edges\n",
    "category_ids_per_page = game_category_edges[1]\n",
    "h_data['game', 'has_category', 'category'].edge_attr = category_embeddings_projected[category_ids_per_page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895aea52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[   10,   332,    18,  ...,  9620,  9973, 14727],\n",
       "        [  618,   618,   618,  ...,   553,   553,   553]]), 'edge_attr': tensor([0.0059, 0.0000, 0.0006,  ..., 0.0004, 0.0013, 0.0005], device='cuda:0')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Undirection to h_data\n",
    "h_data = ToUndirected()(h_data)\n",
    "h_data[('genre', 'rev_has_genre', 'game')].edge_attr = genre_embeddings_projected[genre_ids_per_edge]\n",
    "h_data['game', 'rev_plays', 'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b8b5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new architecture, different convolution approach singe SAGEConv does not support edge attributes\n",
    "from torch_geometric.nn import HeteroConv, NNConv\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, num_users, num_games, num_genres, num_categories, embedding_dimensions=64, edge_dims=None):\n",
    "        super().__init__()\n",
    "        self.user_embed = nn.Embedding(num_users, embedding_dimensions).to(device)\n",
    "        self.game_embed = nn.Embedding(num_games, embedding_dimensions).to(device)\n",
    "        self.genre_embed = nn.Embedding(num_genres, embedding_dimensions).to(device)\n",
    "        self.category_embed = nn.Embedding(num_categories, embedding_dimensions).to(device)\n",
    "\n",
    "        def edge_nn(in_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, embedding_dimensions),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embedding_dimensions, embedding_dimensions * embedding_dimensions)\n",
    "            ).to(device)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            HeteroConv({\n",
    "                edge_type: NNConv(\n",
    "                    in_channels=(embedding_dimensions, embedding_dimensions),\n",
    "                    out_channels=embedding_dimensions,\n",
    "                    nn=edge_nn(edge_dims[edge_type])\n",
    "                ).to(device)\n",
    "                for edge_type in edge_dims\n",
    "            }, aggr='sum')\n",
    "        ])\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n",
    "        x_dict = {\n",
    "            'user': self.user_embed(x_dict['user'].to(device)),\n",
    "            'game': self.game_embed(x_dict['game'].to(device)),\n",
    "            'genre': self.genre_embed(x_dict['genre'].to(device)),\n",
    "            'category': self.category_embed(x_dict['category'].to(device)),\n",
    "        }\n",
    "        x_dict = self.convs[0](x_dict, edge_index_dict, edge_attr_dict)\n",
    "        return x_dict\n",
    "\n",
    "    \n",
    "#same LP as before\n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, embedding_dimensions):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 * embedding_dimensions, embedding_dimensions),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dimensions, 1)\n",
    "        ).to(device)\n",
    "    def forward(self, i, j):\n",
    "        X = torch.cat([i,j], dim=-1)\n",
    "        return torch.sigmoid(self.net(X)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2fa1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attribute dictionary\n",
    "edge_attr_dict = {\n",
    "    ('user', 'plays', 'game'): h_data['user', 'plays', 'game'].edge_attr.view(-1, 1),\n",
    "    ('game', 'has_genre', 'genre'): h_data['game', 'has_genre', 'genre'].edge_attr,\n",
    "    ('game', 'has_category', 'category'): torch.ones(h_data['game', 'has_category', 'category'].edge_index.size(1), 1),\n",
    "    ('game', 'rev_plays', 'user'): h_data['user', 'plays', 'game'].edge_attr.view(-1, 1),\n",
    "    ('genre', 'rev_has_genre', 'game'): h_data['genre', 'rev_has_genre', 'game'].edge_attr,\n",
    "    ('category', 'rev_has_category', 'game'): torch.ones(h_data['category', 'rev_has_category', 'game'].edge_index.size(1), 1),\n",
    "}\n",
    "edge_attr_dict = {k: v.to(device) for k, v in edge_attr_dict.items()} # Put everything on gpu \n",
    "edge_dims = {k: v.shape[1] for k, v in edge_attr_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1b36d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('user', 'plays', 'game'): torch.Size([499103, 1])\n",
      "('game', 'has_genre', 'genre'): torch.Size([1251103, 64])\n",
      "('game', 'has_category', 'category'): torch.Size([3864253, 1])\n",
      "('game', 'rev_plays', 'user'): torch.Size([499103, 1])\n",
      "('genre', 'rev_has_genre', 'game'): torch.Size([1251103, 64])\n",
      "('category', 'rev_has_category', 'game'): torch.Size([3864253, 1])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for dimensions. Every 3rd thing matches\n",
    "for k, v in edge_attr_dict.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa37a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = GNN(\n",
    "    num_users=h_data['user'].num_nodes,\n",
    "    num_games=h_data['game'].num_nodes,\n",
    "    num_genres=h_data['genre'].num_nodes,\n",
    "    num_categories=h_data['category'].num_nodes,\n",
    "    edge_dims = edge_dims,\n",
    "    embedding_dimensions=64\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6083ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictor with batches\n",
    "predictor = LinkPredictor(64).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()), lr=0.001)\n",
    "h_data = h_data.to(device)\n",
    "\n",
    "# === Create Positive and Negative Edge Pairs ===\n",
    "positive_edges = h_data['user', 'plays', 'game'].edge_index.t().tolist()\n",
    "\n",
    "def sample_batch(batch_size=256):\n",
    "    pos_samples = random.sample(positive_edges, batch_size)\n",
    "    user_nodes = h_data['user'].x.tolist()\n",
    "    game_nodes = h_data['game'].x.tolist()\n",
    "    neg_samples = [[random.choice(user_nodes), random.choice(game_nodes)]\n",
    "                   for _ in range(batch_size)\n",
    "                   if [random.choice(user_nodes), random.choice(game_nodes)] not in positive_edges]\n",
    "    return pos_samples, neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8470c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/50 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 19.09 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 9.76 GiB is allocated by PyTorch, and 23.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m edges \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(pos_edges \u001b[38;5;241m+\u001b[39m neg_edges, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[0;32m     10\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(pos_edges)),\n\u001b[0;32m     11\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(neg_edges))\n\u001b[0;32m     12\u001b[0m ])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 14\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m users, games \u001b[38;5;241m=\u001b[39m edges[:, \u001b[38;5;241m0\u001b[39m], edges[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     16\u001b[0m user_emb, game_emb \u001b[38;5;241m=\u001b[39m x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m][users]\u001b[38;5;241m.\u001b[39mto(device), x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame\u001b[39m\u001b[38;5;124m'\u001b[39m][games]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 39\u001b[0m, in \u001b[0;36mGNN.forward\u001b[1;34m(self, x_dict, edge_index_dict, edge_attr_dict)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict, edge_attr_dict):\n\u001b[0;32m     33\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embed(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)),\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_embed(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)),\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenre_embed(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)),\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory_embed(x_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)),\n\u001b[0;32m     38\u001b[0m     }\n\u001b[1;32m---> 39\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[1;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m conv(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[0;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py:108\u001b[0m, in \u001b[0;36mNNConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[0;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.nn_conv_NNConv_propagate_sxpwkj4w.py:183\u001b[0m, in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[0;32m    174\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[0;32m    175\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    176\u001b[0m                 edge_attr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[0;32m    180\u001b[0m             )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py:120\u001b[0m, in \u001b[0;36mNNConv.message\u001b[1;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_attr: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 120\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels_l, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmatmul(x_j\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), weight)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\anima\\.conda\\envs\\transformers\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 19.09 GiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 9.76 GiB is allocated by PyTorch, and 23.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 50\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_edges, neg_edges = sample_batch()\n",
    "    edges = torch.tensor(pos_edges + neg_edges, dtype=torch.long).to(device)\n",
    "    labels = torch.cat([\n",
    "        torch.ones(len(pos_edges)),\n",
    "        torch.zeros(len(neg_edges))\n",
    "    ]).to(device)\n",
    "\n",
    "    x_dict = model(h_data.x_dict, h_data.edge_index_dict, edge_attr_dict)\n",
    "    users, games = edges[:, 0], edges[:, 1]\n",
    "    user_emb, game_emb = x_dict['user'][users].to(device), x_dict['game'][games].to(device)\n",
    "    preds = predictor(user_emb, game_emb)\n",
    "\n",
    "    loss = F.binary_cross_entropy(preds, labels)\n",
    "    acc = (preds >= 0.5).float().eq(labels).float().mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {loss.item():.4f} | Accuracy: {acc.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
